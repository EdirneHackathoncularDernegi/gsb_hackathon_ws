import os
import pickle
import requests
import streamlit as st
import fitz  # PyMuPDF for PDF text extraction
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# ---------------- LANGCHAIN & FAISS KÃœTÃœPHANELERÄ° ----------------
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq

# ---------------- STREAMLIT OPTION MENU ----------------
from streamlit_option_menu import option_menu

# -------------------------------------------------------
#                    AYARLAR & DEÄÄ°ÅKENLER
# -------------------------------------------------------
load_dotenv()
st.set_page_config(page_title="SoruCAN", page_icon=":robot_face:", layout="centered")

VECTOR_STORE_PATH = "vector_store.pkl"       # OluÅŸturulacak / yÃ¼klenilecek vektÃ¶r deposu
PDF_FOLDER_PATH   = "source"                 # PDFâ€™lerin bulunduÄŸu klasÃ¶r
LINKS_TXT_PATH    = "links.txt"              # Linklerin bulunduÄŸu txt dosyasÄ±

# -------------------------------------------------------
#                    FONKSÄ°YONLAR
# -------------------------------------------------------

# 1) GROQ API Key'i environment'tan alma
def get_api_key() -> str:
    return os.getenv("GROQ_API_KEY", "")

# 2) HuggingFace Inference API Key'i environment'tan alma
def get_inference_api_key() -> str:
    return os.getenv("INFERENCE_API_KEY", "")

# 3) Sidebar Ã¼zerinde API Key uyarÄ±larÄ± ve kontrol
def sidebar_api_key_configuration() -> str:
    groq_api_key = get_api_key()
    if not groq_api_key:
        st.sidebar.warning('Enter the API Key(s) ğŸ—ï¸')
        st.session_state.prompt_activation = False
    elif groq_api_key.startswith('gsk_') and len(groq_api_key) == 56:
        st.sidebar.success(' ', icon='ğŸ‘‰')
        st.session_state.prompt_activation = True
    else:
        st.sidebar.warning('Please enter the correct API Key ğŸ—ï¸!', icon='âš ï¸')
        st.session_state.prompt_activation = False
    return groq_api_key

# 4) Sidebar: Model seÃ§imi
def sidebar_groq_model_selection() -> str:
    st.sidebar.subheader("Model SeÃ§imi")
    return st.sidebar.selectbox(
        'Groq Modeli SeÃ§in',
        ('Llama3-8b-8192', 'Llama3-70b-8192', 'Mixtral-8x7b-32768', 'Gemma-7b-it'),
        label_visibility="collapsed"
    )

# 5) PDFâ€™den metin okuma (fitz ile)
def extract_text_from_pdf(pdf_path):
    try:
        doc = fitz.open(pdf_path)
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()

        if not text.strip():
            raise ValueError("PDF'den metin Ã§Ä±karÄ±lamadÄ±.")

        return text
    except Exception as e:
        st.error(f"PDF iÅŸleme sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")
        return ""

# 6) Mevcut vektÃ¶r deposunu yÃ¼kleme
def load_previous_data():
    if os.path.exists(VECTOR_STORE_PATH):
        with open(VECTOR_STORE_PATH, "rb") as f:
            return pickle.load(f)
    return None

# 7) VektÃ¶r deposunu pickle ile kaydetme
def save_vectorstore(vectorstore):
    with open(VECTOR_STORE_PATH, "wb") as f:
        pickle.dump(vectorstore, f)

# 8) Metinleri chunk'lara bÃ¶lme
def split_data(text: str):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    return text_splitter.split_text(text)

# 9) HuggingFace Inference API bazlÄ± embedding fonksiyonu
def get_embedding_function():
    inference_api_key = get_inference_api_key()
    if not inference_api_key:
        st.error("HuggingFace Inference API key not found")
        return None
    return HuggingFaceInferenceAPIEmbeddings(
        api_key=inference_api_key,
        model_name="sentence-transformers/all-MiniLM-l6-v2"
    )

# 10) TXT dosyasÄ±ndan linkleri okuma
def read_links_from_txt(txt_path: str) -> list:
    """
    Var olan bir txt dosyasÄ±ndaki linkleri satÄ±r satÄ±r okur,
    'http' ile baÅŸlayanlarÄ± bir listeye ekleyerek dÃ¶ndÃ¼rÃ¼r.
    """
    if not os.path.exists(txt_path):
        return []
    try:
        with open(txt_path, "r", encoding="utf-8") as file:
            links = [line.strip() for line in file if line.strip().startswith("http")]
        return links
    except Exception as e:
        st.error(f"TXT dosyasÄ±ndan link okuma sÄ±rasÄ±nda bir hata oluÅŸtu: {e}")
        return []

# 11) Linklerden HTTP ile veri Ã§ekme (requests + BeautifulSoup)
def fetch_data_from_links(links: list) -> list:
    data_list = []
    for link in links:
        try:
            response = requests.get(link, timeout=10)
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                text = soup.get_text(separator="\n", strip=True)
                data_list.append(text)
            else:
                st.warning(f"BaÄŸlantÄ± baÅŸarÄ±sÄ±z: {link} (Durum Kodu: {response.status_code})")
        except Exception as e:
            st.warning(f"BaÄŸlantÄ± Ã§ekme sÄ±rasÄ±nda hata: {link}, Hata: {e}")
    return data_list

# 12) FAISS tabanlÄ± vektÃ¶r deposu oluÅŸturma
def create_vectorstore_from_texts(text_list):
    embeddings = get_embedding_function()
    if not embeddings:
        return None
    try:
        return FAISS.from_texts(texts=text_list, embedding=embeddings)
    except Exception as e:
        st.error(f"VektÃ¶r deposu oluÅŸturulurken hata: {str(e)}")
        return None

# 13) Hem PDFâ€™lerden hem linklerden gelen metinleri birleÅŸtirip vektÃ¶r deposu oluÅŸturan fonksiyon
def create_or_update_vectorstore(pdf_files: list, link_texts: list):
    """
    PDFâ€™lerden okunan metinlerle linklerden Ã§ekilen dÃ¼z metinleri bir araya getirir,
    chunk'lar ve FAISS vektÃ¶r deposu oluÅŸturur.
    """
    # PDF tarafÄ±
    pdf_text = ""
    for pdf_file in pdf_files:
        pdf_text += extract_text_from_pdf(pdf_file)

    # Linklerden gelen veri tarafÄ±
    combined_link_text = "\n".join(link_texts)

    # Ä°ki kaynaÄŸÄ± birleÅŸtir
    combined_text = pdf_text + "\n" + combined_link_text

    # BoÅŸsa uyarÄ±
    if not combined_text.strip():
        st.error("Ne PDFâ€™den ne de linklerden metin elde edilemedi.")
        return None

    # Metni chunk'lara bÃ¶l
    chunks = split_data(combined_text)
    if not chunks:
        st.error("Metin chunk'lara ayrÄ±lamadÄ±.")
        return None

    # FAISS vektÃ¶r deposunu oluÅŸtur
    vector_store = create_vectorstore_from_texts(chunks)
    if vector_store:
        save_vectorstore(vector_store)
        st.success("Veri tabanÄ± (vektÃ¶r deposu) baÅŸarÄ±yla oluÅŸturuldu/gÃ¼ncellendi!")
        return vector_store
    return None

# 14) Soruya yanÄ±t almak iÃ§in LangChain zincirlerini oluÅŸturan fonksiyon
def get_llm_response(llm, prompt_template, question: str) -> dict:
    """
    Mevcut vektÃ¶r deposunu kullanarak retrieval chain oluÅŸturur
    ve LLM'e sorulan soruya cevap dÃ¶ndÃ¼rÃ¼r.
    """
    try:
        # Retrieval zinciri iÃ§in Document Chain
        document_chain = create_stuff_documents_chain(llm, prompt_template)

        # VektÃ¶r deposu yoksa uyarÄ±
        if "vector_store" not in st.session_state or not st.session_state.vector_store:
            return {"answer": "VektÃ¶r deposu bulunamadÄ±. LÃ¼tfen Ã¶nce PDF/link verilerini yÃ¼kleyin."}

        # VektÃ¶r deposunu bir retriever olarak kullan
        retrieval_chain = create_retrieval_chain(
            st.session_state.vector_store.as_retriever(),
            document_chain
        )
        # Soruyu zincire ilet
        response = retrieval_chain.invoke({'input': question})
        return response
    except Exception as e:
        st.error(f"Error getting response: {str(e)}")
        return {"answer": "Bir hata oluÅŸtu."}

# -------------------------------------------------------
#                    OTURUM DURUMU
# -------------------------------------------------------

if "vector_store" not in st.session_state:
    st.session_state.vector_store = load_previous_data()
if "response" not in st.session_state:
    st.session_state.response = None
if "prompt_activation" not in st.session_state:
    st.session_state.prompt_activation = bool(st.session_state.vector_store)
if "conversation" not in st.session_state:
    st.session_state.conversation = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = None
if "prompt" not in st.session_state:
    st.session_state.prompt = False
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "Sana nasÄ±l yardÄ±mcÄ± olabilirim?"}]

# -------------------------------------------------------
#                    SIDEBAR
# -------------------------------------------------------
st.sidebar.header('YapÄ±landÄ±rma')
groq_api_key = sidebar_api_key_configuration()
model = sidebar_groq_model_selection()

# -------------------------------------------------------
#                    ANA SAYFA
# -------------------------------------------------------
st.title("SoruCAN :robot_face:")
st.write("*SorularÄ±na Cevap, Hedeflerine Destek*")
st.write(':blue[***Powered by Matiricie***]')

# Option Menu
selected = option_menu(
    menu_title=None,
    options=["SoruCAN", "HakkÄ±nda"],
    icons=["robot", "bi-file-text-fill"],
    orientation="horizontal",
)

# LLM OluÅŸtur
llm = ChatGroq(groq_api_key=groq_api_key, model_name=model)

# Prompt Åablonu
prompt = ChatPromptTemplate.from_template(
    """
Sen, siber gÃ¼venlik alanÄ±nda uzman bir yardÄ±mcÄ± yapay zekasÄ±n. KullanÄ±cÄ±, lise dÃ¼zeyinde olup siber gÃ¼venlikte kendini geliÅŸtirmek isteyen bir Ã¶ÄŸrencidir. KullanÄ±cÄ±nÄ±n seviyesine uygun, adÄ±m adÄ±m bir plan, kaynak Ã¶nerileri, kurs ve etkinlik tavsiyeleri vermekle gÃ¶revlisin. AÃ§Ä±klamalarÄ±n hem teorik hem pratik boyutu iÃ§ermeli, somut Ã¶nerilere ve kaynaklara (web siteleri, kurslar, konferanslar, CTF yarÄ±ÅŸmalarÄ±, vs.) yer vermelisin.
TÃ¼rkÃ§e konuÅŸuyorsun ve kullanÄ±cÄ±dan gelen sorulara TÃ¼rkÃ§e yanÄ±tlar vermelisin.
    <context>
    {context}
    </context>

    Sorular:
    {input}
    """
)

# -------------------------------------------------------
#                    "SORUCAN" SEKME
# -------------------------------------------------------
if selected == "SoruCAN":

    # 1) PDF KlasÃ¶rÃ¼nÃ¼ Otomatik Tara
    st.subheader("1) PDF KlasÃ¶rÃ¼nÃ¼ Otomatik Tara ve Metinleri Al")
    if not os.path.exists(PDF_FOLDER_PATH):
        st.error(f"Belirtilen klasÃ¶r bulunamadÄ±: {PDF_FOLDER_PATH}")
    else:
        pdf_files = [
            os.path.join(PDF_FOLDER_PATH, file) 
            for file in os.listdir(PDF_FOLDER_PATH) 
            if file.endswith(".pdf")
        ]
        if not pdf_files:
            st.warning("KlasÃ¶rde analiz edilecek PDF bulunamadÄ±.")
        else:
            if st.button("PDF DosyalarÄ±nÄ± Ä°ÅŸle"):
                with st.spinner("PDF dosyalarÄ± iÅŸleniyor..."):
                    # 2) Linklerden veri Ã§ek
                    links = read_links_from_txt(LINKS_TXT_PATH)
                    link_data_list = fetch_data_from_links(links)
                    # Hem PDFâ€™ler hem link metinleri -> tek vektÃ¶r deposu
                    st.session_state.vector_store = create_or_update_vectorstore(pdf_files, link_data_list)
                    st.session_state.prompt = True

    st.divider()

    # 2) Sohbet EkranÄ±
    st.subheader("2) Soru-Cevap")
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if question := st.chat_input(
        placeholder='YÃ¼klenen PDF + linklerden elde edilen veriye dayanarak sorunuzu yazÄ±n...',
        disabled=not st.session_state.prompt
    ):
        # KullanÄ±cÄ± mesajÄ±
        st.session_state.messages.append({"role": "user", "content": question})
        st.chat_message("user").write(question)

        # YanÄ±t alma
        with st.spinner('Ä°ÅŸleniyor...'):
            st.session_state.response = get_llm_response(llm, prompt, question)
            answer = st.session_state.response.get('answer', 'Bir hata oluÅŸtu.')
            st.session_state.messages.append({"role": "assistant", "content": answer})
            st.chat_message("assistant").write(answer)

# -------------------------------------------------------
#                    "HAKKINDA" SEKME
# -------------------------------------------------------
elif selected == "HakkÄ±nda":

    with st.expander("Bu Uygulama Hangi BÃ¼yÃ¼k Dil Modellerini Destekliyor?"):
        st.markdown('''Groq tarafÄ±ndan desteklenen aÅŸaÄŸÄ±daki LLM'leri destekler:
- **Llama3-8b-8192**
- **Llama3-70b-8192**
- **Mixtral-8x7b-32768**
- **Gemma-7b-it**''')

    with st.expander("Bu Uygulama Hangi KÃ¼tÃ¼phaneyi VektÃ¶r Deposu iÃ§in KullanÄ±yor?"):
        st.markdown('''Bu uygulama, AI benzerlik aramasÄ± ve vektÃ¶r deposu iÃ§in **FAISS** kÃ¼tÃ¼phanesini kullanÄ±r.''')

    with st.expander("SoruCAN Nedir ve Ne Ä°ÅŸe Yarar?"):
        st.markdown('''**SoruCAN**, HedefGenÃ§ platformunun yapay zeka destekli asistanÄ±dÄ±r. GenÃ§lerin kariyer planlamasÄ±, iÅŸ ve staj fÄ±rsatlarÄ±, eÄŸitim Ã¶nerileri gibi konularda sorularÄ±nÄ± yanÄ±tlar ve rehberlik saÄŸlar. KiÅŸisel hedeflerinize ulaÅŸmanÄ±z iÃ§in size Ã¶zel Ã¶neriler sunar.''')

    with st.expander("SoruCANâ€™a Hangi TÃ¼r SorularÄ± Sorabilirim?"):
        st.markdown('''SoruCANâ€™a kariyer ve kiÅŸisel geliÅŸimle ilgili birÃ§ok soru sorabilirsiniz. Ã–rnek sorular:
- â€œHangi mesleÄŸe daha yatkÄ±nÄ±m?â€
- â€œCVâ€™mi nasÄ±l geliÅŸtirebilirim?â€
- â€œYakÄ±nÄ±mda hangi kariyer etkinlikleri var?â€
- â€œBir staj bulmak iÃ§in ne yapmalÄ±yÄ±m?â€''')

    with st.expander("SoruCAN NasÄ±l DoÄŸru Ã–neriler Sunuyor?"):
        st.markdown('''SoruCAN, sizin profil bilgilerinizi (ilgi alanlarÄ±nÄ±z, kariyer hedefleriniz) ve sistemdeki fÄ±rsatlarÄ± analiz ederek Ã¶nerilerde bulunur. AyrÄ±ca, yapay zeka desteÄŸi sayesinde sorularÄ±nÄ±za hÄ±zlÄ± ve gÃ¼venilir yanÄ±tlar verir.''')

    with st.expander("SoruCANâ€™a VerdiÄŸim Bilgiler GÃ¼venli mi?"):
        st.markdown('''Evet, SoruCANâ€™a saÄŸladÄ±ÄŸÄ±nÄ±z bilgiler tamamen gÃ¼vendedir. KiÅŸisel bilgileriniz yalnÄ±zca platform iÃ§indeki Ã¶neriler ve rehberlik iÃ§in kullanÄ±lÄ±r. HedefGenÃ§, veri gÃ¼venliÄŸiniz iÃ§in tÃ¼m yasal dÃ¼zenlemelere uyar.''')


